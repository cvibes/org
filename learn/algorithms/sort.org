#+TITLE: Sorting

* Foundation

The =sort= method will only refer to data through =less= and =exch=, listed below. Restriction
data access to these two operations makes our code readable and portable, and makes it easier for
us certify that algorithms are correct, to study performance and to compare algorithms. 

When studying sorting algorithms, we count /compares/ and /exchanges/. For algorithms that do not
use exchanges, we count /array accesses/.

#+BEGIN_SRC java
private static boolean less(Comparable v, Comparable w)
{
    return v.compareTo(w) < 0;
}

private static void exch(Comparable[] a, int i, int j)
{
    Comparable t = a[i];
    a[i] = a[j];
    a[j] = t;
}
#+END_SRC

* Elementary sort

** Selection Sort

First, find the smallest item in the array and exchange it with the first entry. Then find the next smallest
item and exchange it with the second entry. Continue until the entire array is sorted.

*** Code

#+BEGIN_SRC java
/**
 * Algorithm 2.1 Selection Sort
 */
public class Selection
{
    public static void sort(Comparable[] a)
    {
        int N = a.length;
        for (int i = 0; i < N; i++){
            int min = i;
            for (int j = i + 1; j < N; j++)
                if (less(a[j], a[min]) ) min = j;
        }
        exch(a, i, min);
    }
}
#+END_SRC

*** Performance

Uses ~N^2/2 compares and N exchanges to sort an array of length N.

For each item from 0 to i-1, there's one exchange and N-i-1 compares.

*Running time is insensitive to input*.  Each pass has to go through all remaining items to find 
next smallest item.

*Data movement is minimal.*  Number of exchanges is a linear function of the array size, each pass
exchange once. 

** Insertion Sort

Consider each item and move it into its proper place among the already considered.

*** Code

#+BEGIN_SRC java
/**
 * Algorithm 2.2 Insertion Sort
 */
public class Insertion
{
    public static void sort(Comparable[] a)
    {
        int N = a.length;
        for (int i = 1; i < N; i++)
            for (int j = i; j > 0 && less(a[j], a[j-1]); j--)
                exch(a, j, j-1);
    }
}
#+END_SRC

*** Performance

Uses ~N^2/4 compares and ~N^2/4 exchanges to sort array of lenght N on average. Worst case
is ~N^2/2 compares and ~N^2/2 exchanges; best case is N-1 compares and 0 exchanges.

 - On a sorted array or if all keys are same, insertion sort takes /linear/ time.
 - On a /partially sorted/ array (where number of inversions is less than a constant multiple of size), insertion
   sort is efficient. Partially sorted array includes:
   - each entry is not far from its final position
   - a small array appended to a large sorted array.
   - only a few entries that are not in place.
 - Insertion works well for arrays of small size, or partially sorted arrays even if it's huge.

** Shell Sort

Shell sort is an extension of insertion sort that gains speed by allowing exchanges
of array entries that are far apart, to produce partially sorted arrays that can be
efficiently sorted, eventually by insertion sort.

The idea is to rearrange the array to give it the property that taking every /h/th
entry (starting anywhere) yields a sorted subsequence. Such an array is said to be
/h/-sorted. By /h/-sorting for some large values of /h/, we can move items in the
array long distances and thus make it easier to /h/-sort for smaller values of
/h/. Using such a procedure for any sequence of values of /h/ that ends in 1 will
produce a sorted array: this is shellsort.

*** Code

#+BEGIN_SRC java
/**
 * Algorithm 2.3 Shellsort
 */

public class Shell
{
    public static void sort(Comparable[] a)
    {
        int N = a.length;
        int h = 1;
        while ( h < N/3 ) h = 3 * h + 1;   // 1, 4, 13, 40, 121, 364, 1003...
        while ( h >= 1){
            for (int i = h; i < N; i++) Insert a[i] among a[i-h], a[i-2*h], a[i-3*h]...
                for( int j = i; j >= h && less(a[j], a[j-h]); j -= h; )
                    exch(a, j, j-h);
        }
        h = h/3;
    }
}
#+END_SRC

*** Performance

Shellsort is much faster than insertion sort and selection sort, the its speed advantage increases
with the array size. But its exact running time is hard to analyze. It's better than quadratic, the 
worst case number of compares is proportional to N^3/2.


* Merge Sort

/Merge sort/ is based on /merging/: combining two ordered arrays to make one
larger ordered array.  This naturally leads to a recursive solution: to sort an
array, divide it into halves, sort the two halves recursively, and then merge
the results. It guarantees to sort any array of N items in time proprotional to
/NlogN/. Its prime disadvantage is that it uses extra space proportional to /N/.

** Top-down merge sort

#+BEGIN_SRC java
/**
 * Algorithm 2.4 Top-down merge sort
 */
public class Merge
{
    private static Comparable[] aux;     // auxiliary array for merges

    private static void merge(Comparable[] a, int lo, int mid, int hi)
    {   // Merge a[lo .. mid] with a[mid+1 .. hi]
        int i = lo, j = mid + 1;
        for (int k = lo; k <= hi; k++)    // Copy a[lo .. hi] to aux[lo .. hi]
            aux[k] = a[k];

        for( int k = lo; k <= hi; k++ )
            if      (i > mid)              a[k] = aux[j++];
            else if (j > hi)               a[k] = aux[i++];
            else if (less(aux[j], aux[i])) a[k] = aux[j++];
            else                           a[k] = aux[i++];
    }

    public static void sort(Comparable[] a)
    {
        aux = new Comparable[a.length];   // allocate space just once
        sort(a, 0, a.length - 1);
    }

    public static void sort(Comparable[] a, int lo, int hi)
    {   // sort a[lo..hi]
        if ( hi <= lo ) return;
        int mid = lo + (hi - lo) / 2;
        sort(a, lo, mid);
        sort(a, mid+1, hi);
        merge(a, lo, mid, hid);
    }
}
#+END_SRC

** Bottom-up merge sort

#+BEGIN_SRC java
/**
 *  Bottom-up Merge Sort
 */
public class MergeBU
{
    private static Comparable[] aux;
    // merge code see above
    public static void sort(Comparable[] a)
    {
        int N = a.length;
        aux = new Comparable[N];
        for (int sz = 1; sz < N; sz = sz + sz)
            for (int lo = 0; lo < N-sz; lo += sz + sz)
                merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1));
    }
}

#+END_SRC

** Performance

Both top-down and bottom-up merge sort use between 1/2 * NlgN and NlgN compares
and at most 6NlgN array accesses to sort an array of length N.

*Improvements*

  - Use insertion sort for small sub arrays. Cutoff at 15 can improve performance by 10% - 15%
  - By testing if =a[mid]= is equal or less than =a[mid+1]=, call to =merge()= can be skipped.
  - Alternate between input and auxiliary arrays can save copying time.

* Quicksort

Quicksort is mostly widely used sorting algorithm because it's easy to
implement, works well for a variety of different kinds of input data, and is
substantially faster than any other sorting method in typical applications. It
sorts data in-place and requires time proprotional to /NlogN/ on the average. It
has a shorter inner loop than most other sorting algorithms, which means that
it is fast in practice as well as in theory. Its primary drawback is that it is
fragile in the sense that some care is involved in the implementation to be sure
to avoid bad performance. Mistakes can lead to quadratic performance.

** Design

Quicksort is a divide-and-conquer method for sorting. It works by /partitioning/
an array into two subarrays, then sorting the subarrays independently. In
mergesort, we break the array into two subarrays to be sorted and then combine
the ordered subarrays to make the whole ordered array; for quicksort, we
rearrange the array such that, when the two subarrays are sorted, the whole
array is ordered. In mergesort, we do the two recursive calls /before/ working
on the whole array; in quicksort, we do the two recursive calls /after/ working
on the whole array. For mergesort, the array is divided as half; for quicksort,
the position of the partition depends on the contents of the array.

** Code

#+BEGIN_SRC java
public class Quick
{
    private static int partition(Comparable[] a, int lo, int hi)
    {
        int i = lo, j = hi + 1;
        Comparable v = a[lo];
        while ( true ){  // Scan right, scan left, check for scan complete, and exchange
            while (less(a[++i], v) ) if ( i == hi ) break;
            while (less(v, a[--j]) ) if ( j == lo ) break;
            if ( i >= j ) break;
            exch(a, i, j);
        }
        exch(a, lo, j);
        return j;
    }

    public static void sort(Comparable[] a)
    {
        StdRandom.shuffle(a);
        sort(a, 0, a.length - 1);
    }

    private static void sort(Comparable a[], int lo, int hi)
    {
        if ( hi <= lo ) return;
        int j = partition(a, lo, hi);
        sort(a, lo, j-1);
        sort(a, j+1, hi);
    }
}
#+END_SRC

The partitioning process re-arranges the array to make the three conditions
hold:

  - The entry =a[j]= is in its final place in the array, for some j.
  - No entry in =a[lo]= through =a[j-1]= is greater than =a[j]=.
  - No entry in =a[j]= through =a[hi]= is less than =a[j]=.


* Heaps, Priority Queues and Heat Sort

The /binary heap/ is a data structure that can efficiently support the basic
priority-queue operations. In a binary heap, the key in each node is larger than
or equal to its two children. 

A /complete binary tree/ starts at top, and proceed down the levels until all N
nodes are filled.  It provides the opportunity to use a compact array
representation that does not involve explicit links: root at position 1, its
children at position 2 and 3, their children in positions 4, 5, 6 and 7, and so
on. The parent of an node =k= is =int(k/2)=, and its children are =2k= and =2k+1=.

When the priority of some node is increased, or a new node is added at the
bottom of the heap, we have to travel /up the heap to restore the heap order.
When the priority of some node is decreased, like replace the root node with a
node that has a smaller key, we have to travel /down/ the heap.

** Ideas of operations in binary heap

*Bottom-up reheapify (swim)*

In this case we keep exchanging the out-of-order node with its parent until we
reach a node with a larger key, or the root.

*Top-down reheapify (sink)*

In this case we keep exchanging the out-of-order node with the /larger/ of its
two children until we reach a node with both children smaller or equal, or the
bottom.

We use =swim()= and =sink()= to implement the operations in Priority Queues:

*Insert*

We add the new key at the end of the array, increment the size of the heap, then
swim up through the heap with that key to restore the heap condition.

*Remove the maximum*

We take the largest item off the top, put the item from the end of the heap at
the top, decrement the size of the heap, then sink down through the heap.

** Code

#+BEGIN_SRC java
public class MaxPQ<Key extends Comparable<Key>>
{
    private Key[] pq;
    private int N = 0;

    private boolean less(int i, int j)
    { return pq[i].compareTo(pq[j]) < 0; }

    private void exch(int i, int j)
    { Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; }

    private void swim(int k)
    {
        while ( k > 1 && less(k/2, k) ){
            exch(k/2, k);
            k = k/2;
        }
    }

    private void sink(int k)
    {
        while ( 2*k <= N ){
            int j = 2*k;
            if ( j < N && less(j, j+1)) j++;
            if ( !less(k, j) )  break;
            exch(k, j);
            k = j;
        }
    }

    public boolean isEmpty()
    { return N == 0; }

    public int size()
    { return N; };

    public void insert(Key v)
    {
        pq[++N] = v;
        swim(N);
    }

    public Key delMax()
    {
        Key max = pq[1];
        exch(1, N--);
        pq[N+1] = null;
        sink(1);
        return max;
    }
}
#+END_SRC

** Heap Sort

Heapsort has two phases: heap construction and sort down. In heap construction we 
transform the array into the heap structure. The simple and naive way to do so is
to go through the items from left to right, and use =swim()= to construct the heap.
It would have =Nlog(N)= performance. A much better way to is to go from right to
left and use =sink()= to construct the heap.

*** Construction

Every position in the array is the root of a subheap, =sink()= works for such
subheaps. If the two children of a node are heaps, then calling =sink()= on that
node make the subtree rooted at the parent a heap. This process establishes the 
heap order inductively. 

The scan starts halfway back through the array because we can skip the subheaps 
of size 1.  It ends at position 1, when we finish building the heap with one call
to =sink()=. 

Sink-based heap construction uses fewer than /2N/ compares and fewer than /N/ 
exchanges.

*** Sort down

In this phase we remove the largest key and put it in the vacated position. It's 
a bit like selection sort but uses much fewer compares and exchanges because of the
heap structure.

Heapsort uses fewer than /2Nlog(N) + 2N/ compares and half that many exchanges. /2N/
covers cost for heap construction. /2Nlog(N)/ follows from bounding the cost of each 
sink operation during the sortdown by /2log(N)/

*** Code

#+BEGIN_SRC java

public static void sort(Comparable[] a)
{
    int N = a.length;
    for (int k = N/2; k >= 1; k++)
        sink(a, k, N);

    while( N > 1 ){
        exch(a, 1, N--);
        sink(a, 1, N);
    }
}
#+END_SRC
